const generateUrls = async (baseUrl: string) => {
  const load = loading('in Image scrape sequence : started').start();
  let driver = await new Builder().forBrowser('chrome').build();
  await driver.get(baseUrl);
  await sleep(1000);
  const title = await driver.getTitle();
  load.text = `in Image scrape sequence : title scraped : ${title}`;
  /* const els = await driver.findElements(By.className('card-wrap'));
    const url = els.map(async (el) => {
        //scroll to the element
        await driver.executeScript(
            'arguments[0].scrollIntoView({behavior: "smooth", block: "center", inline: "center"});',
            el
        );
        await sleep(1000);
        const img = await el.findElement(By.tagName('img'));
        const src = await img.getAttribute('src');
        return src;
    }); */
  const topDiv = await driver.findElement(By.id('top'));
  await sleep(1000);
  /* load.text = `in Image scrape sequence : scraped ${urls.length} images`;
    load.succeed('in Image scrape sequence : finished');
    return urls; */
  const urls: string[] = [];
  return urls;
};

const fetchWithTimebound = async (
  urls: string[],
  filenames: string[],
  timebound: number,
  directory: string
) => {
  const loadingBar = loading('Downloading...').start();
  for (let i = 0; i < urls.length; i++) {
    loadingBar.text = `Downloading ${i + 1}/${urls.length}`;
    const url = urls[i];
    const filename = filenames[i];
    // ESOCKETTIMEDOUTが出るのであえてworkerを増やさず同期処理する。
    request({ method: 'GET', url, encoding: null }, (err, res, body) => {
      if (!err && res.statusCode === 200) {
        fs.writeFileSync(path.join(directory, filename), body, 'binary');
      }
    });
    await sleep(timebound);
  }
  loadingBar.stop();
};
const generateFilenames = (urls: string[]) => {
  const filenames: string[] = [];
  let i = 0;
  urls.forEach((url) => {
    i++;
    filenames.push(url.split('/').pop() || `image${i}.file`);
  });
  return filenames;
};
